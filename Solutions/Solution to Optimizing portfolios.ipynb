{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'C:\\\\Coding\\\\Local_repositories\\\\Exammmmm\\\\')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy import optimize\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# pd.set_option('display.float_format', '{:.4f}'.format) # 4 decimals are shown in pandas dataframes\n",
    "\n",
    "from OwnCodeLib import four_deci\n",
    "from codelib.visualization.base import fan_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "asset = {}\n",
    "\n",
    "for i in range(1, 11):\n",
    "    asset[i] = pd.read_csv(\"C:\\\\Coding\\\\Local_repositories\\\\Exammmmm\\\\ExamData\\\\asset_{}.csv\".format(i), index_col = 0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear and cumulative returns and log returns\n",
    "\n",
    "lin_ret = {}\n",
    "cum_lin_ret = {}\n",
    "log_ret = {}\n",
    "cum_log_ret = {}\n",
    "\n",
    "for i in asset:\n",
    "    lin_ret[i] = asset[i][:] / asset[i][:].shift(1) - 1\n",
    "    cum_lin_ret[i] = (lin_ret[i] + 1).cumprod() - 1\n",
    "    log_ret[i] = np.log(asset[i][:] / asset[i][:].shift(1))\n",
    "    cum_log_ret[i] = log_ret[i].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive stats 1 year horizon\n",
    "\n",
    "horizon = 1\n",
    "columns = [\"Mean\", \"Standard deviation\", \"Skewness\", \"Kurtosis\", \"5th percentile\", \"95th percentile\"]\n",
    "oneypricedescr = pd.DataFrame(columns = columns, index = range(1, 11))\n",
    "oneyretdescr = pd.DataFrame(columns = columns, index = range(1, 11))\n",
    "\n",
    "for i, j in zip(asset, range(1, 11)):\n",
    "    oneypricedescr[\"Mean\"].loc[j] = (asset[i].iloc[horizon, :].mean())\n",
    "    oneypricedescr[\"Standard deviation\"].loc[j] = (asset[i].iloc[horizon, :].std())\n",
    "    oneypricedescr[\"Skewness\"].loc[j] = (asset[i].iloc[horizon, :].skew())\n",
    "    oneypricedescr[\"Kurtosis\"].loc[j] = (asset[i].iloc[horizon, :].kurtosis())\n",
    "    oneypricedescr[\"5th percentile\"].loc[j] = (asset[i].iloc[horizon, :].quantile(0.05))\n",
    "    oneypricedescr[\"95th percentile\"].loc[j] = (asset[i].iloc[horizon, :].quantile(0.95))\n",
    "    oneyretdescr[\"Mean\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].mean())\n",
    "    oneyretdescr[\"Standard deviation\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].std())\n",
    "    oneyretdescr[\"Skewness\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].skew())\n",
    "    oneyretdescr[\"Kurtosis\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].kurtosis())\n",
    "    oneyretdescr[\"5th percentile\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].quantile(0.05))\n",
    "    oneyretdescr[\"95th percentile\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].quantile(0.95))   \n",
    "print(oneypricedescr.to_latex())\n",
    "print(oneyretdescr.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive stats 5 year horizon\n",
    "\n",
    "horizon = 5\n",
    "columns = [\"Mean\", \"Standard deviation\", \"Skewness\", \"Kurtosis\", \"5th percentile\", \"95th percentile\"]\n",
    "fiveypricedescr = pd.DataFrame(columns = columns, index = range(1, 11))\n",
    "fiveyretdescr = pd.DataFrame(columns = columns, index = range(1, 11))\n",
    "\n",
    "for i, j in zip(asset, range(1, 11)):\n",
    "    fiveypricedescr[\"Mean\"].loc[j] = (asset[i].iloc[horizon, :].mean())\n",
    "    fiveypricedescr[\"Standard deviation\"].loc[j] = (asset[i].iloc[horizon, :].std())\n",
    "    fiveypricedescr[\"Skewness\"].loc[j] = (asset[i].iloc[horizon, :].skew())\n",
    "    fiveypricedescr[\"Kurtosis\"].loc[j] = (asset[i].iloc[horizon, :].kurtosis())\n",
    "    fiveypricedescr[\"5th percentile\"].loc[j] = (asset[i].iloc[horizon, :].quantile(0.05))\n",
    "    fiveypricedescr[\"95th percentile\"].loc[j] = (asset[i].iloc[horizon, :].quantile(0.95))\n",
    "    fiveyretdescr[\"Mean\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].mean())\n",
    "    fiveyretdescr[\"Standard deviation\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].std())\n",
    "    fiveyretdescr[\"Skewness\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].skew())\n",
    "    fiveyretdescr[\"Kurtosis\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].kurtosis())\n",
    "    fiveyretdescr[\"5th percentile\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].quantile(0.05))\n",
    "    fiveyretdescr[\"95th percentile\"].loc[j] = (cum_lin_ret[i].iloc[horizon, :].quantile(0.95))   \n",
    "print(fiveypricedescr.to_latex())\n",
    "print(fiveyretdescr.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1 year return distributions\n",
    "\n",
    "horizon = 1\n",
    "bins = 50\n",
    "\n",
    "fig, ax = plt.subplots(5, 2, figsize = (15, 15), sharex = True, sharey = True)\n",
    "order_one = [0, 0, 1, 1, 2, 2, 3, 3, 4, 4]\n",
    "order_two = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "\n",
    "for j, k, i in zip(order_one, order_two, range(1, 11)):\n",
    "    x = np.linspace(start = -1, stop = cum_lin_ret[i].iloc[horizon, :].max(), num = 1000)\n",
    "    ax[j][k].hist(cum_lin_ret[i].iloc[horizon, :], bins = bins, density = True)\n",
    "    ax[j][k].plot(x, stats.norm.pdf(x, loc = cum_lin_ret[i].iloc[horizon, :].mean(), scale = cum_lin_ret[i].iloc[horizon, :].std()), label = \"Normal PDF\")\n",
    "    ax[j][k].plot(x, stats.lognorm.pdf(x + 1, scale = np.exp(cum_log_ret[i].iloc[horizon, :].mean()), s = cum_log_ret[i].iloc[horizon, :].std()), label = \"Lognormal PDF\")\n",
    "    \n",
    "    ax[j][k].set_title(\"Asset {}\".format(i))\n",
    "    ax[j][k].legend()\n",
    "\n",
    "ax[4][0].set_xlabel(\"Return (decimal)\") \n",
    "ax[4][1].set_xlabel(\"Return (decimal)\")     \n",
    "    \n",
    "ax[0][0].set_ylabel(\"Density\")\n",
    "ax[1][0].set_ylabel(\"Density\") \n",
    "ax[2][0].set_ylabel(\"Density\") \n",
    "ax[3][0].set_ylabel(\"Density\") \n",
    "ax[4][0].set_ylabel(\"Density\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 year return distributions\n",
    "\n",
    "horizon = 5\n",
    "lims = [-0.75, 0.75]\n",
    "bins = 50\n",
    "\n",
    "fig, ax = plt.subplots(5, 2, figsize = (15, 15), sharex = True, sharey = True)\n",
    "order_one = [0, 0, 1, 1, 2, 2, 3, 3, 4, 4]\n",
    "order_two = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "\n",
    "for j, k, i in zip(order_one, order_two, range(1, 11)):\n",
    "    x = np.linspace(start = -1, stop = cum_lin_ret[i].iloc[horizon, :].max(), num = 1000)\n",
    "    ax[j][k].hist(cum_lin_ret[i].iloc[horizon, :], bins = bins, density = True)\n",
    "    ax[j][k].plot(x, stats.norm.pdf(x, loc = cum_lin_ret[i].iloc[horizon, :].mean(), scale = cum_lin_ret[i].iloc[horizon, :].std()), label = \"Normal PDF\")\n",
    "    ax[j][k].plot(x, stats.lognorm.pdf(x + 1, scale = np.exp(cum_log_ret[i].iloc[horizon, :].mean()), s = cum_log_ret[i].iloc[horizon, :].std()), label = \"Lognormal PDF\")\n",
    "    \n",
    "    ax[j][k].set_title(\"Asset {}\".format(i))\n",
    "    ax[j][k].legend()\n",
    "\n",
    "ax[4][0].set_xlabel(\"Return (decimal)\") \n",
    "ax[4][1].set_xlabel(\"Return (decimal)\")     \n",
    "    \n",
    "ax[0][0].set_ylabel(\"Density\")\n",
    "ax[1][0].set_ylabel(\"Density\") \n",
    "ax[2][0].set_ylabel(\"Density\") \n",
    "ax[3][0].set_ylabel(\"Density\") \n",
    "ax[4][0].set_ylabel(\"Density\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equally weighted\n",
    "\n",
    "pf_ew_ret = (lin_ret[1] + lin_ret[2] + lin_ret[3] + lin_ret[4] + lin_ret[5] + lin_ret[6] + lin_ret[7] + lin_ret[8] + lin_ret[9] + lin_ret[10]) / len(lin_ret)\n",
    "pf_ew_price = ((pf_ew_ret + 1).cumprod() - 1).fillna(0) + 1\n",
    "pf_ew_price_np = pf_ew_price.to_numpy()\n",
    "\n",
    "# Buy and hold\n",
    "\n",
    "pf_bh_price = (asset[1] + asset[2] + asset[3] + asset[4] + asset[5] + asset[6] + asset[7] + asset[8] + asset[9] + asset[10]) / len(asset)\n",
    "pf_bh_price_np = pf_bh_price.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of prices\n",
    "\n",
    "x = np.linspace(0, 5, 6)\n",
    "\n",
    "percentiles_pf_ew_price_np = np.percentile(pf_ew_price_np, [0.5, 1.0, 2.5, 5, 10, 50, 90, 95, 97.5, 99.0, 99.5], axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5), sharex = True, sharey = True)\n",
    "\n",
    "fan_chart(x,\n",
    "          percentiles_pf_ew_price_np,\n",
    "          labels=['99% CI', '98% CI', '95% CI', '90% CI', '80% CI', 'Median'],\n",
    "          ax = ax[0])\n",
    "\n",
    "ax[0].set_xlabel(\"Year\")\n",
    "ax[0].set_ylabel(\"Price\")\n",
    "ax[0].set_title(\"Equally weighted\")\n",
    "\n",
    "ax[0].legend(loc='upper left');\n",
    "\n",
    "percentiles_pf_bh_price_np = np.percentile(pf_bh_price_np, [0.5, 1.0, 2.5, 5, 10, 50, 90, 95, 97.5, 99.0, 99.5], axis=1)\n",
    "\n",
    "fan_chart(x,\n",
    "          percentiles_pf_bh_price_np,\n",
    "          labels=['99% CI', '98% CI', '95% CI', '90% CI', '80% CI', 'Median'],\n",
    "          ax = ax[1])\n",
    "\n",
    "ax[1].set_xlabel(\"Year\")\n",
    "\n",
    "ax[1].set_title(\"Buy and hold\")\n",
    "\n",
    "ax[1].legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equally weighted returns and cumulative returns\n",
    "\n",
    "pf_ew_ret = pf_ew_price / pf_ew_price.shift(1) - 1\n",
    "pf_ew_cum_ret = (1 + pf_ew_ret).cumprod() - 1\n",
    "\n",
    "# Buy and hold returns and cumulative returns\n",
    "\n",
    "pf_bh_ret = pf_bh_price / pf_bh_price.shift(1) - 1\n",
    "pf_bh_cum_ret = (1 + pf_bh_ret).cumprod() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 year portfolio returns descriptive statistics for both EW and BH\n",
    "\n",
    "horizon = 1\n",
    "columns = [\"Mean\", \"Standard deviation\", \"Skewness\", \"Kurtosis\", \"95% VaR\", \"95% CVaR\"]\n",
    "index = [\"EW\", \"BH\"]\n",
    "oneypfdescr = pd.DataFrame(columns = columns, index = index)\n",
    "\n",
    "# Equally weighted\n",
    "\n",
    "oneypfdescr[\"Mean\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].mean()\n",
    "oneypfdescr[\"Standard deviation\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].std()\n",
    "oneypfdescr[\"Skewness\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].skew()\n",
    "oneypfdescr[\"Kurtosis\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].kurtosis()\n",
    "oneypfdescr[\"95% VaR\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].quantile(0.05)\n",
    "oneypfdescr[\"95% CVaR\"].loc[\"EW\"] = np.mean(pf_ew_cum_ret.iloc[horizon, :][pf_ew_cum_ret.iloc[horizon, :] <= pf_ew_cum_ret.iloc[horizon, :].quantile(0.05)])\n",
    "\n",
    "# Buy and hold\n",
    "\n",
    "oneypfdescr[\"Mean\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].mean()\n",
    "oneypfdescr[\"Standard deviation\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].std()\n",
    "oneypfdescr[\"Skewness\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].skew()\n",
    "oneypfdescr[\"Kurtosis\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].kurtosis()\n",
    "oneypfdescr[\"95% VaR\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].quantile(0.05)\n",
    "oneypfdescr[\"95% CVaR\"].loc[\"BH\"] = np.mean(pf_bh_cum_ret.iloc[horizon, :][pf_bh_cum_ret.iloc[horizon, :] <= pf_bh_cum_ret.iloc[horizon, :].quantile(0.05)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneypfdescr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 year portfolio returns descriptive statistics for both EW and BH\n",
    "\n",
    "horizon = 5\n",
    "columns = [\"Mean\", \"Standard deviation\", \"Skewness\", \"Kurtosis\", \"95% VaR\", \"95% CVaR\"]\n",
    "index = [\"EW\", \"BH\"]\n",
    "fiveypfdescr = pd.DataFrame(columns = columns, index = index)\n",
    "\n",
    "# Equally weighted\n",
    "\n",
    "fiveypfdescr[\"Mean\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].mean()\n",
    "fiveypfdescr[\"Standard deviation\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].std()\n",
    "fiveypfdescr[\"Skewness\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].skew()\n",
    "fiveypfdescr[\"Kurtosis\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].kurtosis()\n",
    "fiveypfdescr[\"95% VaR\"].loc[\"EW\"] = pf_ew_cum_ret.iloc[horizon, :].quantile(0.05)\n",
    "fiveypfdescr[\"95% CVaR\"].loc[\"EW\"] = np.mean(pf_ew_cum_ret.iloc[horizon, :][pf_ew_cum_ret.iloc[horizon, :] <= pf_ew_cum_ret.iloc[horizon, :].quantile(0.05)])\n",
    "\n",
    "# Buy and hold\n",
    "\n",
    "fiveypfdescr[\"Mean\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].mean()\n",
    "fiveypfdescr[\"Standard deviation\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].std()\n",
    "fiveypfdescr[\"Skewness\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].skew()\n",
    "fiveypfdescr[\"Kurtosis\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].kurtosis()\n",
    "fiveypfdescr[\"95% VaR\"].loc[\"BH\"] = pf_bh_cum_ret.iloc[horizon, :].quantile(0.05)\n",
    "fiveypfdescr[\"95% CVaR\"].loc[\"BH\"] = np.mean(pf_bh_cum_ret.iloc[horizon, :][pf_bh_cum_ret.iloc[horizon, :] <= pf_bh_cum_ret.iloc[horizon, :].quantile(0.05)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiveypfdescr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 year portfolio returns distributions for both EW and BH\n",
    "\n",
    "horizon = 1\n",
    "bins = 50\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (15, 5), sharex = True, sharey = True)\n",
    "\n",
    "ax[0].hist(pf_ew_cum_ret.iloc[horizon, :], bins = bins, density = True)\n",
    "ax[0].axvline(oneypfdescr[\"95% VaR\"].loc[\"EW\"], label = \"95% VaR\", color = \"darkgreen\")\n",
    "ax[0].axvline(oneypfdescr[\"95% CVaR\"].loc[\"EW\"], label = \"95% CVaR\", color = \"darkred\")\n",
    "ax[0].set_title(\"Equally weighted\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(pf_bh_cum_ret.iloc[horizon, :], bins = bins, density = True)\n",
    "ax[1].axvline(oneypfdescr[\"95% VaR\"].loc[\"BH\"], label = \"95% VaR\", color = \"darkgreen\")\n",
    "ax[1].axvline(oneypfdescr[\"95% CVaR\"].loc[\"BH\"], label = \"95% CVaR\", color = \"darkred\")\n",
    "ax[1].set_title(\"Buy and hold\")\n",
    "ax[1].legend()\n",
    "\n",
    "ax[0].set_xlabel(\"Return (decimal)\") \n",
    "ax[1].set_xlabel(\"Return (decimal)\")        \n",
    "ax[0].set_ylabel(\"Density\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 year portfolio returns distributions for both EW and BH\n",
    "\n",
    "horizon = 5\n",
    "bins = 50\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (15, 5), sharex = True, sharey = True)\n",
    "\n",
    "ax[0].hist(pf_ew_cum_ret.iloc[horizon, :], bins = bins, density = True)\n",
    "ax[0].axvline(fiveypfdescr[\"95% VaR\"].loc[\"EW\"], label = \"95% VaR\", color = \"darkgreen\")\n",
    "ax[0].axvline(fiveypfdescr[\"95% CVaR\"].loc[\"EW\"], label = \"95% CVaR\", color = \"darkred\")\n",
    "ax[0].set_title(\"Equally weighted\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(pf_bh_cum_ret.iloc[horizon, :], bins = bins, density = True)\n",
    "ax[1].axvline(fiveypfdescr[\"95% VaR\"].loc[\"BH\"], label = \"95% VaR\", color = \"darkgreen\")\n",
    "ax[1].axvline(fiveypfdescr[\"95% CVaR\"].loc[\"BH\"], label = \"95% CVaR\", color = \"darkred\")\n",
    "ax[1].set_title(\"Buy and hold\")\n",
    "ax[1].legend()\n",
    "\n",
    "ax[0].set_xlabel(\"Return (decimal)\") \n",
    "ax[1].set_xlabel(\"Return (decimal)\")        \n",
    "ax[0].set_ylabel(\"Density\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert the dictionary into a 3D numpy array\n",
    "\n",
    "cum_lin_ret_np = np.array(list(cum_lin_ret.values())).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal portfolio weights (buy and hold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimization of standard deviation\n",
    "\n",
    "# Objective function\n",
    "\n",
    "def OptPFWeightsMinStd(w: np.array, horizon: int, cum_lin_ret_np: np.array):\n",
    "    \"\"\"Finds standard deviation of the returns of a buy and hold portfolio for a given horizon\"\"\"\n",
    "    pf_return = (cum_lin_ret_np @ w).T\n",
    "    return pf_return[horizon, :].std(ddof=1)\n",
    "\n",
    "# Minimization of CVaR\n",
    "\n",
    "# Objective function\n",
    "\n",
    "def OptPFWeightsMinCVaR(w: np.array, horizon: int, cum_lin_ret_np: np.array, alpha: int = 95):\n",
    "    \"\"\"Finds CVaR of the returns of a buy and hold portfolio for a given horizon\"\"\"\n",
    "    pf_return = (cum_lin_ret_np @ w).T\n",
    "    return abs(np.mean(pf_return[horizon, :][pf_return[horizon, :] <= np.percentile(pf_return[horizon, :], (100 - alpha))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 year horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints\n",
    "\n",
    "target = 0.08\n",
    "\n",
    "def cons_1(w):\n",
    "    return np.sum(w) - 1\n",
    "\n",
    "def cons_2(w, horizon, cum_lin_ret_np):\n",
    "    return np.mean((cum_lin_ret_np @ w).T[horizon, :]) - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing objective function (standard deviation) w.r.t. weights with target return 8%\n",
    "# 1 year horizon \n",
    "\n",
    "horizon = 1\n",
    "\n",
    "bounds = [(0, 1)] * len(asset) # No shorting constraint\n",
    "args = (horizon, cum_lin_ret_np) # Exogenous input\n",
    "x0 = [1/10] * len(asset) # Initial values\n",
    "constrs = [{\"fun\" : cons_1, \"type\" : \"eq\"}, {\"fun\" : cons_2, \"type\" : \"eq\", \"args\" : (horizon, cum_lin_ret_np)}] # Weights must sum to 1\n",
    "\n",
    "optwstdoney = optimize.minimize(fun = OptPFWeightsMinStd, x0 = x0, args = args, constraints = constrs, bounds = bounds, method = \"SLSQP\", options = {'ftol': 1e-9, 'disp': False})\n",
    "optwstdoney.x.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing objective function (CVaR) w.r.t. weights with target return 8%\n",
    "# 1 year horizon \n",
    "\n",
    "horizon = 1\n",
    "\n",
    "bounds = [(0, 1)] * len(asset) # No shorting constraint\n",
    "args = (horizon, cum_lin_ret_np) # Exogenous input\n",
    "x0 = [1/10] * len(asset) # Initial values\n",
    "constrs = [{\"fun\" : cons_1, \"type\" : \"eq\"}, {\"fun\" : cons_2, \"type\" : \"eq\", \"args\" : (horizon, cum_lin_ret_np)}] # Weights must sum to 1\n",
    "\n",
    "optwcvaroney = optimize.minimize(fun = OptPFWeightsMinCVaR, x0 = x0, args = args, constraints = constrs, bounds = bounds, method = \"SLSQP\", options = {'ftol': 1e-9, 'disp': False})\n",
    "optwcvaroney.x.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 year horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraints\n",
    "\n",
    "target = 0.45\n",
    "\n",
    "def cons_1(w):\n",
    "    return np.sum(w) - 1\n",
    "\n",
    "def cons_2(w, horizon, cum_lin_ret_np):\n",
    "    return np.mean((cum_lin_ret_np @ w).T[horizon, :]) - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing objective function (standard deviation) w.r.t. weights with target return 45%\n",
    "# 5 year horizon \n",
    "\n",
    "horizon = 5\n",
    "\n",
    "bounds = [(0, 1)] * len(asset) # No shorting constraint\n",
    "args = (horizon, cum_lin_ret_np) # Exogenous input\n",
    "x0 = [1/10] * len(asset) # Initial values\n",
    "constrs = [{\"fun\" : cons_1, \"type\" : \"eq\"}, {\"fun\" : cons_2, \"type\" : \"eq\", \"args\" : (horizon, cum_lin_ret_np)}] # Weights must sum to 1\n",
    "\n",
    "optwstdfivey = optimize.minimize(fun = OptPFWeightsMinStd, x0 = x0, args = args, constraints = constrs, bounds = bounds, method = \"SLSQP\", options = {'ftol': 1e-9, 'disp': False})\n",
    "optwstdfivey.x.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing objective function (CVaR) w.r.t. weights with target return 45%\n",
    "# 5 year horizon \n",
    "\n",
    "horizon = 5\n",
    "\n",
    "bounds = [(0, 1)] * len(asset) # No shorting constraint\n",
    "args = (horizon, cum_lin_ret_np) # Exogenous input\n",
    "x0 = [1/10] * len(asset) # Initial values\n",
    "constrs = [{\"fun\" : cons_1, \"type\" : \"eq\"}, {\"fun\" : cons_2, \"type\" : \"eq\", \"args\" : (horizon, cum_lin_ret_np)}] # Weights must sum to 1\n",
    "\n",
    "optwcvarfivey = optimize.minimize(fun = OptPFWeightsMinCVaR, x0 = x0, args = args, constraints = constrs, bounds = bounds, method = \"SLSQP\", options = {'ftol': 1e-9, 'disp': False})\n",
    "optwcvarfivey.x.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the optimal portfolio weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 year horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One year optimal portfolio weights for different targets return, minimizing standard deviation\n",
    "\n",
    "targets = np.linspace(0.05, 0.09, 21)\n",
    "opt_weight_std_one_year = list()\n",
    "\n",
    "for target in targets:\n",
    "    def cons_1(w):\n",
    "        return np.sum(w) - 1\n",
    "\n",
    "    def cons_2(w, horizon, cum_lin_ret_np):\n",
    "        return np.mean((cum_lin_ret_np @ w).T[horizon, :]) - target\n",
    "    \n",
    "    # Minimizing objective function (standard deviation) w.r.t. weights with respect to variable target return\n",
    "    # 1 year horizon \n",
    "\n",
    "    horizon = 1\n",
    "\n",
    "    bounds = [(0, 1)] * len(asset) # No shorting constraint\n",
    "    args = (horizon, cum_lin_ret_np) # Exogenous input\n",
    "    x0 = [1/10] * len(asset) # Initial values\n",
    "    constrs = [{\"fun\" : cons_1, \"type\" : \"eq\"}, {\"fun\" : cons_2, \"type\" : \"eq\", \"args\" : (horizon, cum_lin_ret_np)}] # Weights must sum to 1\n",
    "\n",
    "    optwstdoney = optimize.minimize(fun = OptPFWeightsMinStd, x0 = x0, args = args, constraints = constrs, bounds = bounds, method = \"SLSQP\", options = {'ftol': 1e-9, 'disp': False})\n",
    "    optwstdoney.x.round(4)\n",
    "    \n",
    "    opt_weight_std_one_year.append(optwstdoney.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One year optimal portfolio weights for different targets return, minimizing CVaR\n",
    "\n",
    "targets = np.linspace(0.05, 0.09, 21)\n",
    "opt_weight_CVaR_one_year = list()\n",
    "\n",
    "for target in targets:\n",
    "    def cons_1(w):\n",
    "        return np.sum(w) - 1\n",
    "\n",
    "    def cons_2(w, horizon, cum_lin_ret_np):\n",
    "        return np.mean((cum_lin_ret_np @ w).T[horizon, :]) - target\n",
    "    \n",
    "    # Minimizing objective function (CVaR) w.r.t. weights with respect to variable target return\n",
    "    # 1 year horizon \n",
    "\n",
    "    horizon = 1\n",
    "\n",
    "    bounds = [(0, 1)] * len(asset) # No shorting constraint\n",
    "    args = (horizon, cum_lin_ret_np) # Exogenous input\n",
    "    x0 = [1/10] * len(asset) # Initial values\n",
    "    constrs = [{\"fun\" : cons_1, \"type\" : \"eq\"}, {\"fun\" : cons_2, \"type\" : \"eq\", \"args\" : (horizon, cum_lin_ret_np)}] # Weights must sum to 1\n",
    "\n",
    "    optwcvaroney = optimize.minimize(fun = OptPFWeightsMinCVaR, x0 = x0, args = args, constraints = constrs, bounds = bounds, method = \"SLSQP\", options = {'ftol': 1e-9, 'disp': False})\n",
    "    optwcvaroney.x.round(4)\n",
    "    \n",
    "    opt_weight_CVaR_one_year.append(optwcvaroney.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list()\n",
    "\n",
    "for i in range(1, 11):\n",
    "    labels.append(\"Asset {}\".format(i))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (15, 6), sharex = True, sharey = True)\n",
    "\n",
    "ax[0].stackplot(targets, np.array(opt_weight_std_one_year).T, labels = labels)\n",
    "ax[0].set_xlim([targets.min(), targets.max()])\n",
    "ax[0].set_ylim(0, 1)\n",
    "ax[0].set_xlabel(\"Target return (decimal)\")\n",
    "ax[0].set_ylabel(\"Weight (decimal)\")\n",
    "ax[0].legend(loc='center', bbox_to_anchor=(0.5, -0.4), ncol=2);\n",
    "\n",
    "ax[1].stackplot(targets, np.array(opt_weight_CVaR_one_year).T, labels = labels)\n",
    "ax[1].set_xlim([targets.min(), targets.max()])\n",
    "ax[1].set_ylim(0, 1)\n",
    "ax[1].set_xlabel(\"Target return (decimal)\")\n",
    "\n",
    "ax[1].legend(loc='center', bbox_to_anchor=(0.5, -0.4), ncol=2);\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 year horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five year optimal portfolio weights for different targets return, minimizing standard deviation\n",
    "\n",
    "targets = np.linspace(0.3, 0.5, 41)\n",
    "opt_weight_std_five_years = list()\n",
    "\n",
    "for target in targets:\n",
    "    def cons_1(w):\n",
    "        return np.sum(w) - 1\n",
    "\n",
    "    def cons_2(w, horizon, cum_lin_ret_np):\n",
    "        return np.mean((cum_lin_ret_np @ w).T[horizon, :]) - target\n",
    "    \n",
    "    # Minimizing objective function (standard deviation) w.r.t. weights with respect to variable target return\n",
    "    # 5 year horizon \n",
    "\n",
    "    horizon = 5\n",
    "\n",
    "    bounds = [(0, 1)] * len(asset) # No shorting constraint\n",
    "    args = (horizon, cum_lin_ret_np) # Exogenous input\n",
    "    x0 = [1/10] * len(asset) # Initial values\n",
    "    constrs = [{\"fun\" : cons_1, \"type\" : \"eq\"}, {\"fun\" : cons_2, \"type\" : \"eq\", \"args\" : (horizon, cum_lin_ret_np)}] # Weights must sum to 1\n",
    "\n",
    "    optwstdfivey = optimize.minimize(fun = OptPFWeightsMinStd, x0 = x0, args = args, constraints = constrs, bounds = bounds, method = \"SLSQP\", options = {'ftol': 1e-9, 'disp': False})\n",
    "    optwstdfivey.x.round(4)\n",
    "    \n",
    "    opt_weight_std_five_years.append(optwstdfivey.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five year optimal portfolio weights for different targets return, minimizing CVaR\n",
    "\n",
    "targets = np.linspace(0.3, 0.5, 41)\n",
    "opt_weight_CVaR_five_years = list()\n",
    "\n",
    "for target in targets:\n",
    "    def cons_1(w):\n",
    "        return np.sum(w) - 1\n",
    "\n",
    "    def cons_2(w, horizon, cum_lin_ret_np):\n",
    "        return np.mean((cum_lin_ret_np @ w).T[horizon, :]) - target\n",
    "    \n",
    "    # Minimizing objective function (CVaR) w.r.t. weights with respect to variable target return\n",
    "    # 5 year horizon \n",
    "\n",
    "    horizon = 5\n",
    "\n",
    "    bounds = [(0, 1)] * len(asset) # No shorting constraint\n",
    "    args = (horizon, cum_lin_ret_np) # Exogenous input\n",
    "    x0 = [1/10] * len(asset) # Initial values\n",
    "    constrs = [{\"fun\" : cons_1, \"type\" : \"eq\"}, {\"fun\" : cons_2, \"type\" : \"eq\", \"args\" : (horizon, cum_lin_ret_np)}] # Weights must sum to 1\n",
    "\n",
    "    optwcvarfivey = optimize.minimize(fun = OptPFWeightsMinCVaR, x0 = x0, args = args, constraints = constrs, bounds = bounds, method = \"SLSQP\", options = {'ftol': 1e-9, 'disp': False})\n",
    "    optwcvarfivey.x.round(4)\n",
    "    \n",
    "    opt_weight_CVaR_five_years.append(optwcvarfivey.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list()\n",
    "\n",
    "for i in range(1, 11):\n",
    "    labels.append(\"Asset {}\".format(i))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (15, 6), sharex = True, sharey = True)\n",
    "\n",
    "ax[0].stackplot(targets, np.array(opt_weight_std_five_years).T, labels = labels)\n",
    "ax[0].set_xlim([targets.min(), targets.max()])\n",
    "ax[0].set_ylim(0, 1)\n",
    "ax[0].set_xlabel(\"Target return (decimal)\")\n",
    "ax[0].set_ylabel(\"Weight (decimal)\")\n",
    "ax[0].legend(loc='center', bbox_to_anchor=(0.5, -0.4), ncol=2);\n",
    "\n",
    "ax[1].stackplot(targets, np.array(opt_weight_CVaR_five_years).T, labels = labels)\n",
    "ax[1].set_xlim([targets.min(), targets.max()])\n",
    "ax[1].set_ylim(0, 1)\n",
    "ax[1].set_xlabel(\"Target return (decimal)\")\n",
    "\n",
    "ax[1].legend(loc='center', bbox_to_anchor=(0.5, -0.4), ncol=2);\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Views according to Meucci - Fully Flexible Views: Theory and Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: We wish to maximize the Lagrangian dual function w.r.t. the Lagrangian multiplier, v.\n",
    "# Once v is estimated, we can use it to calculate p_thilde - the new probabilities that make sure our view is satisfied by \n",
    "# ultimately changing the prior distribution so that we obtain a posterior distribution, which 1) satisfies our view while 2)\n",
    "# also being as similar to the prior distribution as possible\n",
    "# The optimization problem here stems from the fact that we wish to minimize the relative entropy, i.e., the difference between\n",
    "# the prior and posterior distributions\n",
    "\n",
    "# Function to calculate the new probabilities\n",
    "\n",
    "def calculate_p_tilde(v, p, H_matrix):\n",
    "    \n",
    "    temp = np.log(p) - 1.0 - np.transpose(H_matrix) @ v\n",
    "    \n",
    "    return np.exp(temp)\n",
    "\n",
    "# Lagrangian dual function that we wish to optimize w.r.t. v (Lagrangian multiplier)\n",
    "# This is a Lagrandian *dual* function, because we let x be a function of the Lagrangian multiplier, v, in the sense that\n",
    "# x is defined in terms of the function 'calculate_p_tilde', which is a function of v\n",
    "\n",
    "def lagrangian_dual_function(v, p, H_matrix, h_vector):\n",
    "    \n",
    "    x = calculate_p_tilde(v, p, H_matrix)\n",
    "    x = np.maximum(x, 10 ** (-32))\n",
    "    \n",
    "    lagrangian = x.T @ (np.log(x) - np.log(p)) + v @ (H_matrix @ x - h_vector)\n",
    "    \n",
    "    return -lagrangian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 year horizon: Asset 1, asset 6 and asset 10 -> 5th percentile, asset 2 -> 50th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H matrix specifies the linear equality constraints\n",
    "# We add the constraint that the weights need to sum to one \n",
    "\n",
    "horizon = 1 # Horizon 1 or 5\n",
    "num_sim = 10000 # 10,000 simulations per asset\n",
    "init_probs = np.array([1 / num_sim] * num_sim) # Initial probabilities\n",
    "\n",
    "which_asset = [1, 2, 6, 10] # Which asset we apply a view on\n",
    "which_quantile = [0.05, 0.5, 0.05, 0.05] # The quantile of interest\n",
    "target_for_quantile = [0.85, 1.15, 0.9, 0.9] # The target value we set for the quantile\n",
    "\n",
    "p_tilde_oney = dict()\n",
    "\n",
    "order_one = [0, 0, 1, 1]\n",
    "order_two = [0, 1, 0, 1]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (15,10), sharex = True, sharey = True)\n",
    "\n",
    "for i, j, k, l, m in zip(which_asset, which_quantile, target_for_quantile, order_one, order_two):\n",
    "    \n",
    "    bool_vector = np.array((asset[i].iloc[horizon, :] < k) * 1) # Vector of 1's and 0's\n",
    "    H_matrix = np.vstack((np.ones(num_sim), bool_vector)) # Linear equality constraints\n",
    "    h_vector = np.array([1.0, j]) # Weights add to 1, view on the quantile of interest\n",
    "\n",
    "    # Maximize Lagrangian dual \n",
    "    # x0 are the start values for the Lagrangian multipliers in vector v\n",
    "\n",
    "    res = optimize.minimize(fun = lagrangian_dual_function, x0 = [0.0, 0.0], args = (init_probs, H_matrix, h_vector))\n",
    "\n",
    "    # Calculate p tilde, i.e., the probabilities that makes the posterior distribution satisfy our view(s) while preserving as much\n",
    "    # of the structure of the prior distribution\n",
    "\n",
    "    p_tilde_oney[i] = calculate_p_tilde(res.x, init_probs, H_matrix)\n",
    "    \n",
    "    # Plotting asset distributions\n",
    "    \n",
    "    ax[l, m].hist(asset[i].iloc[horizon, :], bins = 50, density = True, alpha = 0.5, label = \"Prior dist.\")\n",
    "    ax[l, m].hist(asset[i].iloc[horizon, :], bins = 50, weights = p_tilde_oney[i], density = True, alpha = 0.5, label = \"View dist.\")\n",
    "\n",
    "    ax[l, m].set_title(\"Asset {}\".format(i))\n",
    "    ax[l, m].legend()\n",
    "\n",
    "ax[1, 0].set_xlabel('Price')    \n",
    "ax[1, 1].set_xlabel('Price')        \n",
    "ax[0, 0].set_ylabel('Density')    \n",
    "ax[1, 0].set_ylabel('Density') \n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing prior and posterior distribution\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "ax.hist(asset[1].iloc[1, :], bins = 50, density = True, alpha = 0.5, label = \"Prior dist.\")\n",
    "ax.hist(asset[1].iloc[1, :], bins = 50, weights = p_tilde, density = True, alpha = 0.5, label = \"View dist.\")\n",
    "\n",
    "ax.set_xlabel(\"Asset {} price\".format(which_asset))\n",
    "ax.set_ylabel('Density')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_for_python_course",
   "language": "python",
   "name": "venv_for_python_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}